from typing import Any, Dict

from mcp_sql_agent.app.domain.ports import LlmTranslator


def _build_prompt(nl_query: str, schema: Dict[str, Any], dialect: str) -> str:
    """Build the LLM prompt for NL -> SQL translation.

    Args:
        nl_query: Natural language request from the caller.
        schema: Schema metadata used to guide SQL generation.
        dialect: SQL dialect hint (e.g., sqlite, postgresql).
    Returns:
        Prompt string to send to the LLM.
    """
    return (
        "You are a SQL generator.\n"
        "Return ONLY the SQL query, no markdown, no explanation.\n"
        f"Dialect: {dialect}\n\n"
        "Schema:\n"
        f"{schema}\n\n"
        "User request:\n"
        f"{nl_query}\n"
    )


class OpenAiTranslator(LlmTranslator):
    """OpenAI-backed translator for NL -> SQL."""
    def __init__(self, api_key: str, model: str) -> None:
        """Initialize the OpenAI client and validate credentials.

        Args:
            api_key: OpenAI API key.
            model: OpenAI model identifier.
        Raises:
            RuntimeError: When the OpenAI SDK is missing or API key is blank.
        """
        try:
            from openai import AsyncOpenAI
        except Exception as exc:  # pragma: no cover - handled as runtime guidance
            raise RuntimeError(
                "Missing dependency: install openai SDK (pip install openai)."
            ) from exc

        cleaned = api_key.strip()
        if not cleaned:
            raise RuntimeError("OPENAI_API_KEY is not set.")

        self._client = AsyncOpenAI(api_key=cleaned)
        self._model = model

    async def translate(self, nl_query: str, schema: Dict[str, Any], dialect: str) -> str:
        """Translate a natural language query into SQL.

        Args:
            nl_query: Natural language request from the caller.
            schema: Schema metadata used to guide SQL generation.
            dialect: SQL dialect hint (e.g., sqlite, postgresql).
        Returns:
            SQL string generated by the LLM.
        """
        prompt = _build_prompt(nl_query, schema, dialect)
        response = await self._client.chat.completions.create(
            model=self._model,
            temperature=0,
            max_tokens=512,
            messages=[{"role": "user", "content": prompt}],
        )
        return (response.choices[0].message.content or "").strip()
